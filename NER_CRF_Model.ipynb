{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn_crfsuite import CRF\n",
    "from sklearn_crfsuite.metrics import flat_f1_score\n",
    "from sklearn_crfsuite.metrics import flat_classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "     Sentence #           Word   POS    Tag\n0   Sentence: 1            The    DT      O\n1           NaN           wife    NN    REL\n2           NaN           was    VBD      O\n3           NaN         killed   VBD  VIO_V\n4           NaN            by     IN      O\n5           NaN           the     DT      O\n6           NaN        husband    NN  Actor\n7   Sentence: 2            The    DT      O\n8           NaN    grandfather    NN  Actor\n9           NaN        abused    VBD  VIO_V\n10          NaN            his  PRP$      O\n11          NaN       grandson    NN    REL\n12  Sentence: 3           The     DT      O\n13          NaN            man    NN  Actor\n14          NaN       harassed   VBD  VIO_V\n15          NaN  sister-in-law    NN    REL",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sentence #</th>\n      <th>Word</th>\n      <th>POS</th>\n      <th>Tag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Sentence: 1</td>\n      <td>The</td>\n      <td>DT</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>NaN</td>\n      <td>wife</td>\n      <td>NN</td>\n      <td>REL</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>NaN</td>\n      <td>was</td>\n      <td>VBD</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>NaN</td>\n      <td>killed</td>\n      <td>VBD</td>\n      <td>VIO_V</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>NaN</td>\n      <td>by</td>\n      <td>IN</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>NaN</td>\n      <td>the</td>\n      <td>DT</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>NaN</td>\n      <td>husband</td>\n      <td>NN</td>\n      <td>Actor</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Sentence: 2</td>\n      <td>The</td>\n      <td>DT</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>NaN</td>\n      <td>grandfather</td>\n      <td>NN</td>\n      <td>Actor</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>NaN</td>\n      <td>abused</td>\n      <td>VBD</td>\n      <td>VIO_V</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>NaN</td>\n      <td>his</td>\n      <td>PRP$</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>NaN</td>\n      <td>grandson</td>\n      <td>NN</td>\n      <td>REL</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Sentence: 3</td>\n      <td>The</td>\n      <td>DT</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>NaN</td>\n      <td>man</td>\n      <td>NN</td>\n      <td>Actor</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>NaN</td>\n      <td>harassed</td>\n      <td>VBD</td>\n      <td>VIO_V</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>NaN</td>\n      <td>sister-in-law</td>\n      <td>NN</td>\n      <td>REL</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "#Reading the csv file\n",
    "df = pd.read_csv('ner_dataset.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "    Sentence #         Word  POS    Tag\n0  Sentence: 1          The   DT      O\n1          NaN         wife   NN    REL\n2          NaN         was   VBD      O\n3          NaN       killed  VBD  VIO_V\n4          NaN          by    IN      O\n5          NaN         the    DT      O\n6          NaN      husband   NN  Actor\n7  Sentence: 2          The   DT      O\n8          NaN  grandfather   NN  Actor\n9          NaN      abused   VBD  VIO_V",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sentence #</th>\n      <th>Word</th>\n      <th>POS</th>\n      <th>Tag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Sentence: 1</td>\n      <td>The</td>\n      <td>DT</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>NaN</td>\n      <td>wife</td>\n      <td>NN</td>\n      <td>REL</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>NaN</td>\n      <td>was</td>\n      <td>VBD</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>NaN</td>\n      <td>killed</td>\n      <td>VBD</td>\n      <td>VIO_V</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>NaN</td>\n      <td>by</td>\n      <td>IN</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>NaN</td>\n      <td>the</td>\n      <td>DT</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>NaN</td>\n      <td>husband</td>\n      <td>NN</td>\n      <td>Actor</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Sentence: 2</td>\n      <td>The</td>\n      <td>DT</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>NaN</td>\n      <td>grandfather</td>\n      <td>NN</td>\n      <td>Actor</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>NaN</td>\n      <td>abused</td>\n      <td>VBD</td>\n      <td>VIO_V</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "         Sentence # Word POS Tag\ncount             3   16  16  16\nunique            3   15   5   4\ntop     Sentence: 3  The  NN   O\nfreq              1    2   6   7",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sentence #</th>\n      <th>Word</th>\n      <th>POS</th>\n      <th>Tag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>3</td>\n      <td>16</td>\n      <td>16</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>3</td>\n      <td>15</td>\n      <td>5</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>Sentence: 3</td>\n      <td>The</td>\n      <td>NN</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>1</td>\n      <td>2</td>\n      <td>6</td>\n      <td>7</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array(['O', 'REL', 'VIO_V', 'Actor'], dtype=object)"
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "#Displaying the unique Tags\n",
    "df['Tag'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Sentence #    13\nWord           0\nPOS            0\nTag            0\ndtype: int64"
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "#Checking null values, if any.\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(method = 'ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a class to get sentence. Each sentence will be a list of tuples with its tag and POS.\n",
    "class sentence(object):\n",
    "    def __init__(self, df):\n",
    "        self.n_sent = 1\n",
    "        self.df = df\n",
    "        self.empty = False\n",
    "        agg = lambda s : [(w, p, t) for w, p, t in zip(s['Word'].values.tolist(), s['POS'].values.tolist(), s['Tag'].values.tolist())]\n",
    "        self.grouped = self.df.groupby(\"Sentence #\").apply(agg)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "        \n",
    "    def get_text(self):\n",
    "        try:\n",
    "            s = self.grouped['Sentence: {}'.format(self.n_sent)]\n",
    "            self.n_sent +=1\n",
    "            return s\n",
    "        except:\n",
    "            return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'The wife was  killed by  the  husband'"
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "#Displaying one full sentence\n",
    "getter = sentence(df)\n",
    "sentences = [\" \".join([s[0] for s in sent]) for sent in getter.sentences]\n",
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[('The', 'DT', 'O'), ('wife', 'NN', 'REL'), ('was ', 'VBD', 'O'), ('killed', 'VBD', 'VIO_V'), ('by ', 'IN', 'O'), ('the ', 'DT', 'O'), ('husband', 'NN', 'Actor')]\n"
    }
   ],
   "source": [
    "\n",
    "#sentence with its pos and tag.\n",
    "sent = getter.get_text()\n",
    "print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = getter.sentences\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(),\n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "        'postag': postag,\n",
    "        'postag[:2]': postag[:2],\n",
    "    }\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            '-1:postag': postag1,\n",
    "            '-1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "\n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            '+1:postag': postag1,\n",
    "            '+1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, postag, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, postag, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[['O', 'REL', 'O', 'VIO_V', 'O', 'O', 'Actor'],\n ['O', 'Actor', 'VIO_V', 'O', 'REL'],\n ['O', 'Actor', 'VIO_V', 'REL']]"
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "\n",
    "X = [sent2features(s) for s in sentences]\n",
    "y = [sent2labels(s) for s in sentences]\n",
    "y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[[{'bias': 1.0,\n   'word.lower()': 'the',\n   'word[-3:]': 'The',\n   'word[-2:]': 'he',\n   'word.isupper()': False,\n   'word.istitle()': True,\n   'word.isdigit()': False,\n   'postag': 'DT',\n   'postag[:2]': 'DT',\n   'BOS': True,\n   '+1:word.lower()': 'grandfather',\n   '+1:word.istitle()': False,\n   '+1:word.isupper()': False,\n   '+1:postag': 'NN',\n   '+1:postag[:2]': 'NN'},\n  {'bias': 1.0,\n   'word.lower()': 'grandfather',\n   'word[-3:]': 'her',\n   'word[-2:]': 'er',\n   'word.isupper()': False,\n   'word.istitle()': False,\n   'word.isdigit()': False,\n   'postag': 'NN',\n   'postag[:2]': 'NN',\n   '-1:word.lower()': 'the',\n   '-1:word.istitle()': True,\n   '-1:word.isupper()': False,\n   '-1:postag': 'DT',\n   '-1:postag[:2]': 'DT',\n   '+1:word.lower()': 'abused ',\n   '+1:word.istitle()': False,\n   '+1:word.isupper()': False,\n   '+1:postag': 'VBD',\n   '+1:postag[:2]': 'VB'},\n  {'bias': 1.0,\n   'word.lower()': 'abused ',\n   'word[-3:]': 'ed ',\n   'word[-2:]': 'd ',\n   'word.isupper()': False,\n   'word.istitle()': False,\n   'word.isdigit()': False,\n   'postag': 'VBD',\n   'postag[:2]': 'VB',\n   '-1:word.lower()': 'grandfather',\n   '-1:word.istitle()': False,\n   '-1:word.isupper()': False,\n   '-1:postag': 'NN',\n   '-1:postag[:2]': 'NN',\n   '+1:word.lower()': 'his',\n   '+1:word.istitle()': False,\n   '+1:word.isupper()': False,\n   '+1:postag': 'PRP$',\n   '+1:postag[:2]': 'PR'},\n  {'bias': 1.0,\n   'word.lower()': 'his',\n   'word[-3:]': 'his',\n   'word[-2:]': 'is',\n   'word.isupper()': False,\n   'word.istitle()': False,\n   'word.isdigit()': False,\n   'postag': 'PRP$',\n   'postag[:2]': 'PR',\n   '-1:word.lower()': 'abused ',\n   '-1:word.istitle()': False,\n   '-1:word.isupper()': False,\n   '-1:postag': 'VBD',\n   '-1:postag[:2]': 'VB',\n   '+1:word.lower()': 'grandson',\n   '+1:word.istitle()': False,\n   '+1:word.isupper()': False,\n   '+1:postag': 'NN',\n   '+1:postag[:2]': 'NN'},\n  {'bias': 1.0,\n   'word.lower()': 'grandson',\n   'word[-3:]': 'son',\n   'word[-2:]': 'on',\n   'word.isupper()': False,\n   'word.istitle()': False,\n   'word.isdigit()': False,\n   'postag': 'NN',\n   'postag[:2]': 'NN',\n   '-1:word.lower()': 'his',\n   '-1:word.istitle()': False,\n   '-1:word.isupper()': False,\n   '-1:postag': 'PRP$',\n   '-1:postag[:2]': 'PR',\n   'EOS': True}]]"
     },
     "metadata": {},
     "execution_count": 66
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "X_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Help on CRF in module sklearn_crfsuite.estimator object:\n\nclass CRF(sklearn.base.BaseEstimator)\n |  python-crfsuite wrapper with interface siimlar to scikit-learn.\n |  It allows to use a familiar fit/predict interface and scikit-learn\n |  model selection utilities (cross-validation, hyperparameter optimization).\n |  \n |  Unlike pycrfsuite.Trainer / pycrfsuite.Tagger this object is picklable;\n |  on-disk files are managed automatically.\n |  \n |  Parameters\n |  ----------\n |  algorithm : str, optional (default='lbfgs')\n |      Training algorithm. Allowed values:\n |  \n |      * ``'lbfgs'`` - Gradient descent using the L-BFGS method\n |      * ``'l2sgd'`` - Stochastic Gradient Descent with L2 regularization term\n |      * ``'ap'`` - Averaged Perceptron\n |      * ``'pa'`` - Passive Aggressive (PA)\n |      * ``'arow'`` - Adaptive Regularization Of Weight Vector (AROW)\n |  \n |  min_freq : float, optional (default=0)\n |      Cut-off threshold for occurrence\n |      frequency of a feature. CRFsuite will ignore features whose\n |      frequencies of occurrences in the training data are no greater\n |      than `min_freq`. The default is no cut-off.\n |  \n |  all_possible_states : bool, optional (default=False)\n |      Specify whether CRFsuite generates state features that do not even\n |      occur in the training data (i.e., negative state features).\n |      When True, CRFsuite generates state features that associate all of\n |      possible combinations between attributes and labels.\n |  \n |      Suppose that the numbers of attributes and labels are A and L\n |      respectively, this function will generate (A * L) features.\n |      Enabling this function may improve the labeling accuracy because\n |      the CRF model can learn the condition where an item is not predicted\n |      to its reference label. However, this function may also increase\n |      the number of features and slow down the training process\n |      drastically. This function is disabled by default.\n |  \n |  all_possible_transitions : bool, optional (default=False)\n |      Specify whether CRFsuite generates transition features that\n |      do not even occur in the training data (i.e., negative transition\n |      features). When True, CRFsuite generates transition features that\n |      associate all of possible label pairs. Suppose that the number\n |      of labels in the training data is L, this function will\n |      generate (L * L) transition features.\n |      This function is disabled by default.\n |  \n |  c1 : float, optional (default=0)\n |      The coefficient for L1 regularization.\n |      If a non-zero value is specified, CRFsuite switches to the\n |      Orthant-Wise Limited-memory Quasi-Newton (OWL-QN) method.\n |      The default value is zero (no L1 regularization).\n |  \n |      Supported training algorithms: lbfgs\n |  \n |  c2 : float, optional (default=1.0)\n |      The coefficient for L2 regularization.\n |  \n |      Supported training algorithms: l2sgd, lbfgs\n |  \n |  max_iterations : int, optional (default=None)\n |      The maximum number of iterations for optimization algorithms.\n |      Default value depends on training algorithm:\n |  \n |      * lbfgs - unlimited;\n |      * l2sgd - 1000;\n |      * ap - 100;\n |      * pa - 100;\n |      * arow - 100.\n |  \n |  num_memories : int, optional (default=6)\n |      The number of limited memories for approximating the inverse hessian\n |      matrix.\n |  \n |      Supported training algorithms: lbfgs\n |  \n |  epsilon : float, optional (default=1e-5)\n |      The epsilon parameter that determines the condition of convergence.\n |  \n |      Supported training algorithms: ap, arow, lbfgs, pa\n |  \n |  period : int, optional (default=10)\n |      The duration of iterations to test the stopping criterion.\n |  \n |      Supported training algorithms: l2sgd, lbfgs\n |  \n |  delta : float, optional (default=1e-5)\n |      The threshold for the stopping criterion; an iteration stops\n |      when the improvement of the log likelihood over the last\n |      `period` iterations is no greater than this threshold.\n |  \n |      Supported training algorithms: l2sgd, lbfgs\n |  \n |  linesearch : str, optional (default='MoreThuente')\n |      The line search algorithm used in L-BFGS updates. Allowed values:\n |  \n |      * ``'MoreThuente'`` - More and Thuente's method;\n |      * ``'Backtracking'`` - backtracking method with regular Wolfe condition;\n |      * ``'StrongBacktracking'`` -  backtracking method with strong Wolfe\n |        condition.\n |  \n |      Supported training algorithms: lbfgs\n |  \n |  max_linesearch : int, optional (default=20)\n |      The maximum number of trials for the line search algorithm.\n |  \n |      Supported training algorithms: lbfgs\n |  \n |  calibration_eta : float, optional (default=0.1)\n |      The initial value of learning rate (eta) used for calibration.\n |  \n |      Supported training algorithms: l2sgd\n |  \n |  calibration_rate : float, optional (default=2.0)\n |      The rate of increase/decrease of learning rate for calibration.\n |  \n |      Supported training algorithms: l2sgd\n |  \n |  calibration_samples : int, optional (default=1000)\n |      The number of instances used for calibration.\n |      The calibration routine randomly chooses instances no larger\n |      than `calibration_samples`.\n |  \n |      Supported training algorithms: l2sgd\n |  \n |  calibration_candidates : int, optional (default=10)\n |      The number of candidates of learning rate.\n |      The calibration routine terminates after finding\n |      `calibration_samples` candidates of learning rates\n |      that can increase log-likelihood.\n |  \n |      Supported training algorithms: l2sgd\n |  \n |  calibration_max_trials : int, optional (default=20)\n |      The maximum number of trials of learning rates for calibration.\n |      The calibration routine terminates after trying\n |      `calibration_max_trials` candidate values of learning rates.\n |  \n |      Supported training algorithms: l2sgd\n |  \n |  pa_type : int, optional (default=1)\n |      The strategy for updating feature weights. Allowed values:\n |  \n |      * 0 - PA without slack variables;\n |      * 1 - PA type I;\n |      * 2 - PA type II.\n |  \n |      Supported training algorithms: pa\n |  \n |  c : float, optional (default=1)\n |      Aggressiveness parameter (used only for PA-I and PA-II).\n |      This parameter controls the influence of the slack term on the\n |      objective function.\n |  \n |      Supported training algorithms: pa\n |  \n |  error_sensitive : bool, optional (default=True)\n |      If this parameter is True, the optimization routine includes\n |      into the objective function the square root of the number of\n |      incorrect labels predicted by the model.\n |  \n |      Supported training algorithms: pa\n |  \n |  averaging : bool, optional (default=True)\n |      If this parameter is True, the optimization routine computes\n |      the average of feature weights at all updates in the training\n |      process (similarly to Averaged Perceptron).\n |  \n |      Supported training algorithms: pa\n |  \n |  variance : float, optional (default=1)\n |      The initial variance of every feature weight.\n |      The algorithm initialize a vector of feature weights as\n |      a multivariate Gaussian distribution with mean 0\n |      and variance `variance`.\n |  \n |      Supported training algorithms: arow\n |  \n |  gamma : float, optional (default=1)\n |      The tradeoff between loss function and changes of feature weights.\n |  \n |      Supported training algorithms: arow\n |  \n |  verbose : bool, optional (default=False)\n |      Enable trainer verbose mode.\n |  \n |  model_filename : str, optional (default=None)\n |      A path to an existing CRFSuite model.\n |      This parameter allows to load and use existing crfsuite models.\n |  \n |      By default, model files are created automatically and saved\n |      in temporary locations; the preferred way to save/load CRF models\n |      is to use pickle (or its alternatives like joblib).\n |  \n |  Method resolution order:\n |      CRF\n |      sklearn.base.BaseEstimator\n |      builtins.object\n |  \n |  Methods defined here:\n |  \n |  __getstate__(self)\n |  \n |  __init__(self, algorithm=None, min_freq=None, all_possible_states=None, all_possible_transitions=None, c1=None, c2=None, max_iterations=None, num_memories=None, epsilon=None, period=None, delta=None, linesearch=None, max_linesearch=None, calibration_eta=None, calibration_rate=None, calibration_samples=None, calibration_candidates=None, calibration_max_trials=None, pa_type=None, c=None, error_sensitive=None, averaging=None, variance=None, gamma=None, verbose=False, model_filename=None, keep_tempfiles=False, trainer_cls=None)\n |      Initialize self.  See help(type(self)) for accurate signature.\n |  \n |  fit(self, X, y, X_dev=None, y_dev=None)\n |      Train a model.\n |      \n |      Parameters\n |      ----------\n |      X : list of lists of dicts\n |          Feature dicts for several documents (in a python-crfsuite format).\n |      \n |      y : list of lists of strings\n |          Labels for several documents.\n |      \n |      X_dev : (optional) list of lists of dicts\n |          Feature dicts used for testing.\n |      \n |      y_dev : (optional) list of lists of strings\n |          Labels corresponding to X_dev.\n |  \n |  predict(self, X)\n |      Make a prediction.\n |      \n |      Parameters\n |      ----------\n |      X : list of lists of dicts\n |          feature dicts in python-crfsuite format\n |      \n |      Returns\n |      -------\n |      y : list of lists of strings\n |          predicted labels\n |  \n |  predict_marginals(self, X)\n |      Make a prediction.\n |      \n |      Parameters\n |      ----------\n |      X : list of lists of dicts\n |          feature dicts in python-crfsuite format\n |      \n |      Returns\n |      -------\n |      y : list of lists of dicts\n |          predicted probabilities for each label at each position\n |  \n |  predict_marginals_single(self, xseq)\n |      Make a prediction.\n |      \n |      Parameters\n |      ----------\n |      xseq : list of dicts\n |          feature dicts in python-crfsuite format\n |      \n |      Returns\n |      -------\n |      y : list of dicts\n |          predicted probabilities for each label at each position\n |  \n |  predict_single(self, xseq)\n |      Make a prediction.\n |      \n |      Parameters\n |      ----------\n |      xseq : list of dicts\n |          feature dicts in python-crfsuite format\n |      \n |      Returns\n |      -------\n |      y : list of strings\n |          predicted labels\n |  \n |  score(self, X, y)\n |      Return accuracy score computed for sequence items.\n |      \n |      For other metrics check :mod:`sklearn_crfsuite.metrics`.\n |  \n |  ----------------------------------------------------------------------\n |  Data descriptors defined here:\n |  \n |  attributes_\n |      A list of known attributes.\n |  \n |  classes_\n |      A list of class labels.\n |  \n |  num_attributes_\n |      Number of non-zero CRF attributes.\n |  \n |  size_\n |      Size of the CRF model, in bytes.\n |  \n |  state_features_\n |      Dict with state feature coefficients:\n |      ``{(attr_name, label): coef}``\n |  \n |  tagger_\n |      pycrfsuite.Tagger instance.\n |  \n |  transition_features_\n |      Dict with transition feature coefficients:\n |      ``{(label_from, label_to): coef}``\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from sklearn.base.BaseEstimator:\n |  \n |  __repr__(self, N_CHAR_MAX=700)\n |      Return repr(self).\n |  \n |  __setstate__(self, state)\n |  \n |  get_params(self, deep=True)\n |      Get parameters for this estimator.\n |      \n |      Parameters\n |      ----------\n |      deep : bool, default=True\n |          If True, will return the parameters for this estimator and\n |          contained subobjects that are estimators.\n |      \n |      Returns\n |      -------\n |      params : mapping of string to any\n |          Parameter names mapped to their values.\n |  \n |  set_params(self, **params)\n |      Set the parameters of this estimator.\n |      \n |      The method works on simple estimators as well as on nested objects\n |      (such as pipelines). The latter have parameters of the form\n |      ``<component>__<parameter>`` so that it's possible to update each\n |      component of a nested object.\n |      \n |      Parameters\n |      ----------\n |      **params : dict\n |          Estimator parameters.\n |      \n |      Returns\n |      -------\n |      self : object\n |          Estimator instance.\n |  \n |  ----------------------------------------------------------------------\n |  Data descriptors inherited from sklearn.base.BaseEstimator:\n |  \n |  __dict__\n |      dictionary for instance variables (if defined)\n |  \n |  __weakref__\n |      list of weak references to the object (if defined)\n\n"
    }
   ],
   "source": [
    "crf = CRF(algorithm = 'lbfgs',\n",
    "         c1 = 0.1,\n",
    "         c2 = 0.1,\n",
    "         max_iterations = 100,\n",
    "         all_possible_transitions = False)\n",
    "crf.fit(X_train, y_train)\n",
    "help(crf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting on the test set.\n",
    "y_pred = crf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[['O', 'Actor', 'VIO_V', 'O', 'REL']]\n"
    }
   ],
   "source": [
    "print(y_pred)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36464bitbaseconda4c47ada83e3d41c9a55c7d4c7f706f90",
   "display_name": "Python 3.6.4 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}